{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Ensure all dependencies are installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting m2p (from -r requirements.txt (line 12))\n",
      "  Cloning ssh://****@gitlab.utwente.nl/s2219735-bsc-research-project/mesh-to-points.git (to revision main) to /tmp/pip-install-hqxg6667/m2p_d851e24dc487432cabd9c86da5523f23\n",
      "  Running command git clone --filter=blob:none --quiet 'ssh://****@gitlab.utwente.nl/s2219735-bsc-research-project/mesh-to-points.git' /tmp/pip-install-hqxg6667/m2p_d851e24dc487432cabd9c86da5523f23\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we have GPU support, and if not, warn the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import warnings\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    warnings.warn(\"CUDA is not available. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our dataset...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Checking for existing source data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|███████████████████████████████████████████████████████████████████████████| 12311/12311 [07:22<00:00, 27.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 9843 samples\n",
      "Test data size: 2468 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from data_sources.modelnet40 import ModelNet40\n",
    "from models.dataset import PointCloudDataset\n",
    "from typing import List\n",
    "\n",
    "train_folder = \"data/train\"\n",
    "test_folder = \"data/test\"\n",
    "\n",
    "train_dataset: PointCloudDataset = None\n",
    "test_dataset: PointCloudDataset = None\n",
    "\n",
    "if os.path.exists(train_folder) and os.path.exists(test_folder):\n",
    "    print(\"Train and test data found. Reading data...\")\n",
    "    train_files: List[str] = []\n",
    "    test_files: List[str] = []\n",
    "\n",
    "    for root, dirs, files in os.walk(train_folder):\n",
    "        for file in files:\n",
    "            train_files.append(os.path.join(root, file))\n",
    "\n",
    "    for root, dirs, files in os.walk(test_folder):\n",
    "        for file in files:\n",
    "            test_files.append(os.path.join(root, file))\n",
    "\n",
    "    train_dataset = PointCloudDataset(train_files)\n",
    "    test_dataset = PointCloudDataset(test_files)\n",
    "    k = 40\n",
    "else:\n",
    "    classes, train_dataset, test_dataset = ModelNet40.download(\n",
    "        npoints=2500, train_outdir=train_folder, test_outdir=test_folder\n",
    "    )\n",
    "    k = len(classes)\n",
    "\n",
    "print(f\"Training data: {len(train_dataset)} samples\")\n",
    "print(f\"Test data size: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Train a new classifier or load a new pre-trained one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  3224\n"
     ]
    }
   ],
   "source": [
    "from pointnet.train_classification import train_classification\n",
    "from pointnet.model import PointNetCls\n",
    "\n",
    "classifier_path = \"\"  # pointnet/classifier.pth\n",
    "\n",
    "if classifier_path and os.path.exists(classifier_path):\n",
    "    print(f\"Loading existing model from {classifier_path}...\")\n",
    "    classifier = PointNetCls(k=len(train_dataset.classes))\n",
    "    classifier.load_state_dict(torch.load(classifier_path, weights_only=True))\n",
    "    print(\"Classifier loaded successfully.\")\n",
    "else:\n",
    "    classifier = train_classification(\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        k=k,\n",
    "        epochs=25,\n",
    "        outf=\"./pointnet/cls\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a simple classification to get a visualization of our classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from utils.plot import plot_points\n",
    "\n",
    "i = random.randint(0, len(test_dataset) - 1)\n",
    "\n",
    "input_data = test_dataset[i][0].unsqueeze(0)\n",
    "input_data = input_data.transpose(1, 2)\n",
    "\n",
    "classifier.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = classifier(input_data)\n",
    "\n",
    "\n",
    "scores: torch.Tensor = output[0][0]\n",
    "print(\"Scores:\", scores.tolist())\n",
    "print(\n",
    "    f\"Expected class: {test_dataset.classes[int(test_dataset[i][1])]} ({int(test_dataset[i][1])})\",\n",
    ")\n",
    "print(\n",
    "    f\"Predicted class: {test_dataset.classes[scores.argmax().item()]} ({scores.argmax().item()})\"\n",
    ")\n",
    "\n",
    "points = input_data[0].transpose(0, 1).numpy()\n",
    "plot_points(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the segmenter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pointnet.train_segmentation import train_segmentation\n",
    "\n",
    "train_segmentation(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    epochs=25,\n",
    "    class_choice=0,\n",
    "    outf=\"./pointnet/seg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
