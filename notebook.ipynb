{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup\n",
        "\n",
        "Ensure all dependencies are installed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch/, https://download.pytorch.org/whl/torchvision/\n",
            "Requirement already satisfied: torch==2.0.1+cu117 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.0.1+cu117)\n",
            "Requirement already satisfied: torchvision==0.15.2+cu117 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.15.2+cu117)\n",
            "Requirement already satisfied: tensorboard in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (2.18.0)\n",
            "Requirement already satisfied: torch-tb-profiler in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.4.3)\n",
            "Requirement already satisfied: tqdm in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (4.67.1)\n",
            "Requirement already satisfied: numpy in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (1.26.4)\n",
            "Collecting numpy (from -r requirements.txt (line 10))\n",
            "  Using cached numpy-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: pandas in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2.2.3)\n",
            "Requirement already satisfied: plyfile in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (1.1)\n",
            "Requirement already satisfied: requests in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (2.32.3)\n",
            "Requirement already satisfied: open3d in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.19.0)\n",
            "Requirement already satisfied: matplotlib in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (3.10.0)\n",
            "Requirement already satisfied: segments-ai in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (1.11.11)\n",
            "Requirement already satisfied: python-dotenv in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (1.0.1)\n",
            "Collecting torch-points3d (from -r requirements.txt (line 18))\n",
            "  Using cached torch_points3d-1.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in ./.conda/lib/python3.10/site-packages (from torch==2.0.1+cu117->-r requirements.txt (line 3)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in ./.conda/lib/python3.10/site-packages (from torch==2.0.1+cu117->-r requirements.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: sympy in ./.conda/lib/python3.10/site-packages (from torch==2.0.1+cu117->-r requirements.txt (line 3)) (1.13.3)\n",
            "Requirement already satisfied: networkx in ./.conda/lib/python3.10/site-packages (from torch==2.0.1+cu117->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.conda/lib/python3.10/site-packages (from torch==2.0.1+cu117->-r requirements.txt (line 3)) (3.1.5)\n",
            "Requirement already satisfied: triton==2.0.0 in ./.conda/lib/python3.10/site-packages (from torch==2.0.1+cu117->-r requirements.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.conda/lib/python3.10/site-packages (from torchvision==0.15.2+cu117->-r requirements.txt (line 5)) (11.0.0)\n",
            "Requirement already satisfied: cmake in ./.conda/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1+cu117->-r requirements.txt (line 3)) (3.31.2)\n",
            "Requirement already satisfied: lit in ./.conda/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1+cu117->-r requirements.txt (line 3)) (18.1.8)\n",
            "Requirement already satisfied: absl-py>=0.4 in ./.conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 6)) (2.1.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in ./.conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 6)) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./.conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 6)) (3.7)\n",
            "Requirement already satisfied: packaging in ./.conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in ./.conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 6)) (5.29.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in ./.conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 6)) (75.6.0)\n",
            "Requirement already satisfied: six>1.9 in ./.conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 6)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./.conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 6)) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 11)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 11)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 11)) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.10/site-packages (from requests->-r requirements.txt (line 13)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.10/site-packages (from requests->-r requirements.txt (line 13)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.10/site-packages (from requests->-r requirements.txt (line 13)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.10/site-packages (from requests->-r requirements.txt (line 13)) (2024.12.14)\n",
            "Requirement already satisfied: dash>=2.6.0 in ./.conda/lib/python3.10/site-packages (from open3d->-r requirements.txt (line 14)) (2.18.2)\n",
            "Requirement already satisfied: flask>=3.0.0 in ./.conda/lib/python3.10/site-packages (from open3d->-r requirements.txt (line 14)) (3.0.3)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in ./.conda/lib/python3.10/site-packages (from open3d->-r requirements.txt (line 14)) (5.10.4)\n",
            "Requirement already satisfied: configargparse in ./.conda/lib/python3.10/site-packages (from open3d->-r requirements.txt (line 14)) (1.7)\n",
            "Requirement already satisfied: ipywidgets>=8.0.4 in ./.conda/lib/python3.10/site-packages (from open3d->-r requirements.txt (line 14)) (8.1.5)\n",
            "Requirement already satisfied: addict in ./.conda/lib/python3.10/site-packages (from open3d->-r requirements.txt (line 14)) (2.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in ./.conda/lib/python3.10/site-packages (from open3d->-r requirements.txt (line 14)) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in ./.conda/lib/python3.10/site-packages (from open3d->-r requirements.txt (line 14)) (1.6.0)\n",
            "Requirement already satisfied: pyquaternion in ./.conda/lib/python3.10/site-packages (from open3d->-r requirements.txt (line 14)) (0.9.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 15)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 15)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 15)) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 15)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 15)) (3.2.0)\n",
            "Requirement already satisfied: pydantic!=2.4.0,==2.* in ./.conda/lib/python3.10/site-packages (from segments-ai->-r requirements.txt (line 16)) (2.10.4)\n",
            "Requirement already satisfied: types-Pillow>=9.0 in ./.conda/lib/python3.10/site-packages (from segments-ai->-r requirements.txt (line 16)) (10.2.0.20240822)\n",
            "Requirement already satisfied: types-requests==2.* in ./.conda/lib/python3.10/site-packages (from segments-ai->-r requirements.txt (line 16)) (2.32.0.20241016)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.conda/lib/python3.10/site-packages (from pydantic!=2.4.0,==2.*->segments-ai->-r requirements.txt (line 16)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in ./.conda/lib/python3.10/site-packages (from pydantic!=2.4.0,==2.*->segments-ai->-r requirements.txt (line 16)) (2.27.2)\n",
            "Collecting gdown<4.0.0,>=3.12.0 (from torch-points3d->-r requirements.txt (line 18))\n",
            "  Using cached gdown-3.15.0.tar.gz (10 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting hydra-core<0.12.0,>=0.11.2 (from torch-points3d->-r requirements.txt (line 18))\n",
            "  Using cached hydra_core-0.11.3-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting numba<0.51.0,>=0.50.0 (from torch-points3d->-r requirements.txt (line 18))\n",
            "  Using cached numba-0.50.1.tar.gz (2.0 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of torch-points3d to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch-points3d (from -r requirements.txt (line 18))\n",
            "  Using cached torch_points3d-1.2.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting numba<0.50.0,>=0.49.0 (from torch-points3d->-r requirements.txt (line 18))\n",
            "  Using cached numba-0.49.1.tar.gz (2.0 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting torch-points3d (from -r requirements.txt (line 18))\n",
            "  Using cached torch_points3d-1.1.1-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting plyfile (from -r requirements.txt (line 12))\n",
            "  Using cached plyfile-0.7.4-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting pytorch_metric_learning<0.10.0,>=0.9.87.dev0 (from torch-points3d->-r requirements.txt (line 18))\n",
            "  Using cached pytorch_metric_learning-0.9.99-py3-none-any.whl.metadata (35 kB)\n",
            "Collecting scikit-image<0.17.0,>=0.16.2 (from torch-points3d->-r requirements.txt (line 18))\n",
            "  Using cached scikit-image-0.16.2.tar.gz (28.9 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[27 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m /tmp/pip-install-e27ikl5g/scikit-image_6eeede13dfc94824b1f8218f09cb9f01/setup.py:167: DeprecationWarning:\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m   `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
            "  \u001b[31m   \u001b[0m   of the deprecation of `distutils` itself. It will be removed for\n",
            "  \u001b[31m   \u001b[0m   Python >= 3.12. For older Python versions it will remain present.\n",
            "  \u001b[31m   \u001b[0m   It is recommended to use `setuptools < 60.0` for those Python versions.\n",
            "  \u001b[31m   \u001b[0m   For more details, see:\n",
            "  \u001b[31m   \u001b[0m     https://numpy.org/devdocs/reference/distutils_status_migration.html\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m   from numpy.distutils.core import setup\n",
            "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
            "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
            "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
            "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-e27ikl5g/scikit-image_6eeede13dfc94824b1f8218f09cb9f01/setup.py\", line 243, in <module>\n",
            "  \u001b[31m   \u001b[0m     'build_ext': openmp_build_ext(),\n",
            "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-e27ikl5g/scikit-image_6eeede13dfc94824b1f8218f09cb9f01/setup.py\", line 71, in openmp_build_ext\n",
            "  \u001b[31m   \u001b[0m     from numpy.distutils.command.build_ext import build_ext\n",
            "  \u001b[31m   \u001b[0m   File \"/home/jovyan/research-project-python/.conda/lib/python3.10/site-packages/numpy/distutils/command/build_ext.py\", line 16, in <module>\n",
            "  \u001b[31m   \u001b[0m     from numpy.distutils.system_info import combine_paths\n",
            "  \u001b[31m   \u001b[0m   File \"/home/jovyan/research-project-python/.conda/lib/python3.10/site-packages/numpy/distutils/system_info.py\", line 200, in <module>\n",
            "  \u001b[31m   \u001b[0m     from numpy.distutils.command.config import config as cmd_config\n",
            "  \u001b[31m   \u001b[0m   File \"/home/jovyan/research-project-python/.conda/lib/python3.10/site-packages/numpy/distutils/command/config.py\", line 19, in <module>\n",
            "  \u001b[31m   \u001b[0m     from numpy.distutils.mingw32ccompiler import generate_manifest\n",
            "  \u001b[31m   \u001b[0m   File \"/home/jovyan/research-project-python/.conda/lib/python3.10/site-packages/numpy/distutils/mingw32ccompiler.py\", line 27, in <module>\n",
            "  \u001b[31m   \u001b[0m     from distutils.msvccompiler import get_build_version as get_build_msvc_version\n",
            "  \u001b[31m   \u001b[0m ModuleNotFoundError: No module named 'distutils.msvccompiler'\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check if we have GPU support, and if not, warn the user.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA is available!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import warnings\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available!\")\n",
        "else:\n",
        "    warnings.warn(\"CUDA is not available. Running on CPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Settings\n",
        "\n",
        "All our settings are here for convenience.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
            "[Open3D INFO] WebRTC GUI backend enabled.\n",
            "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
            "Seed: 1626838268\n"
          ]
        }
      ],
      "source": [
        "from pole_gen.models import UtilityPoleLabel\n",
        "import secrets\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import warnings\n",
        "from utils.logging import warning_format\n",
        "import os\n",
        "\n",
        "# ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤\n",
        "# ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ No need to modify anything above here! ◢◤ ◢◤ ◢◤ ◢◤ ◢◤\n",
        "# ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤\n",
        "\n",
        "debug: bool = True\n",
        "n_points: int = 1000\n",
        "classes: list = [l.name for l in UtilityPoleLabel]\n",
        "n_classes: int = len(classes)\n",
        "seed: int = secrets.randbits(32)\n",
        "torch.set_float32_matmul_precision(\"medium\")\n",
        "\n",
        "# ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤\n",
        "# ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ No need to modify anything below here! ◢◤ ◢◤ ◢◤ ◢◤ ◢◤\n",
        "# ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤ ◢◤\n",
        "\n",
        "if debug:\n",
        "    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "print(f\"Seed: {seed}\")\n",
        "\n",
        "warnings.formatwarning = warning_format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preparing our Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training & Evaluation Data\n",
        "\n",
        "This data is procedurally generated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data directory found. Using existing training data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6989cd1b2e6045478c656d660e7ffd6a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Checking dataset...:   0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Splitting dataset into training and validation sets...\n",
            "Training dataset size: 800\n",
            "Validation dataset size: 200\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pole_gen.data import generate_data\n",
        "from models.dataset import PointCloudDataset\n",
        "\n",
        "out_path: str = os.path.join(\"data\", \"train\")\n",
        "eval_split: float = 0.2\n",
        "\n",
        "if not os.path.exists(out_path) or len(os.listdir(out_path)) == 0:\n",
        "    print(\"Directory is empty or does not exist. New testing data will be generated.\")\n",
        "    generate_data(\n",
        "        n_samples=1000,\n",
        "        n_points=n_points,\n",
        "        out_dir=out_path,\n",
        "        jitter=0.02,\n",
        "    )\n",
        "else:\n",
        "    print(\"Data directory found. Using existing training data.\")\n",
        "\n",
        "file_paths = [os.path.join(out_path, f) for f in os.listdir(out_path)]\n",
        "generated_dataset = PointCloudDataset(\n",
        "    file_paths=file_paths,\n",
        "    n_points=n_points,\n",
        "    n_classes=n_classes,\n",
        ")\n",
        "\n",
        "generated_dataset.validate()\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "print(\"Splitting dataset into training and validation sets...\")\n",
        "train_size = int((1 - eval_split) * len(generated_dataset))\n",
        "val_size = len(generated_dataset) - train_size\n",
        "train_dataset, eval_dataset = torch.utils.data.random_split(\n",
        "    generated_dataset, [train_size, val_size]\n",
        ")\n",
        "\n",
        "del generated_dataset\n",
        "\n",
        "\n",
        "print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(eval_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing Data\n",
        "\n",
        "This data is manually labeled, real-world laser scanned data. We will fetch this remotely if needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing data directory found. Using existing testing data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "943ae750c99b4388bd32daccb192d9d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Checking dataset...:   0%|          | 0/91 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing dataset size: 91\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from electrical_poles.data import download_data\n",
        "from models.dataset import PointCloudDataset\n",
        "\n",
        "test_data_path = os.path.join(\"data\", \"test\")\n",
        "\n",
        "if not os.path.exists(test_data_path) or len(os.listdir(test_data_path)) == 0:\n",
        "    print(\n",
        "        \"Testing data directory is empty or does not exist. New testing data will be downloaded.\"\n",
        "    )\n",
        "    download_data(out_dir=test_data_path)\n",
        "else:\n",
        "    print(\"Testing data directory found. Using existing testing data.\")\n",
        "\n",
        "file_paths = [os.path.join(test_data_path, f) for f in os.listdir(test_data_path)]\n",
        "test_dataset = PointCloudDataset(\n",
        "    file_paths=file_paths,\n",
        "    n_points=n_points,\n",
        "    n_classes=n_classes,\n",
        ")\n",
        "\n",
        "test_dataset.validate()\n",
        "\n",
        "print(f\"Testing dataset size: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Segmentation\n",
        "\n",
        "Now we can train our segmenter with our data, or load a pre-existing one if needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,     1] loss: 0.223\n",
            "[1,     2] loss: 0.210\n",
            "[1,     3] loss: 0.195\n",
            "[1,     4] loss: 0.185\n",
            "[1,     5] loss: 0.171\n",
            "[1,     6] loss: 0.171\n",
            "[1,     7] loss: 0.161\n",
            "[1,     8] loss: 0.158\n",
            "[1,     9] loss: 0.155\n",
            "[1,    10] loss: 0.141\n",
            "[1,    11] loss: 0.140\n",
            "[1,    12] loss: 0.132\n",
            "[1,    13] loss: 0.132\n",
            "[1,    14] loss: 0.125\n",
            "[1,    15] loss: 0.119\n",
            "[1,    16] loss: 0.118\n",
            "[1,    17] loss: 0.116\n",
            "[1,    18] loss: 0.113\n",
            "[1,    19] loss: 0.104\n",
            "[1,    20] loss: 0.107\n",
            "[1,    21] loss: 0.107\n",
            "[1,    22] loss: 0.106\n",
            "[1,    23] loss: 0.107\n",
            "[1,    24] loss: 0.108\n",
            "[1,    25] loss: 0.096\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([8, 1000]), labels shape: torch.Size([8, 1000])\n",
            "correct 139728 / 200000\n",
            "Valid accuracy: 69 %\n",
            "best_val_acc: 69.864 saving model at data/pointnet/checkpoints/pointnetmodel.yml\n",
            "[2,     1] loss: 0.103\n",
            "[2,     2] loss: 0.088\n",
            "[2,     3] loss: 0.088\n",
            "[2,     4] loss: 0.096\n",
            "[2,     5] loss: 0.087\n",
            "[2,     6] loss: 0.092\n",
            "[2,     7] loss: 0.104\n",
            "[2,     8] loss: 0.098\n",
            "[2,     9] loss: 0.095\n",
            "[2,    10] loss: 0.088\n",
            "[2,    11] loss: 0.083\n",
            "[2,    12] loss: 0.091\n",
            "[2,    13] loss: 0.097\n",
            "[2,    14] loss: 0.081\n",
            "[2,    15] loss: 0.085\n",
            "[2,    16] loss: 0.086\n",
            "[2,    17] loss: 0.074\n",
            "[2,    18] loss: 0.095\n",
            "[2,    19] loss: 0.095\n",
            "[2,    20] loss: 0.081\n",
            "[2,    21] loss: 0.080\n",
            "[2,    22] loss: 0.090\n",
            "[2,    23] loss: 0.086\n",
            "[2,    24] loss: 0.091\n",
            "[2,    25] loss: 0.098\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([8, 1000]), labels shape: torch.Size([8, 1000])\n",
            "correct 139503 / 200000\n",
            "Valid accuracy: 69 %\n",
            "[3,     1] loss: 0.091\n",
            "[3,     2] loss: 0.072\n",
            "[3,     3] loss: 0.094\n",
            "[3,     4] loss: 0.076\n",
            "[3,     5] loss: 0.080\n",
            "[3,     6] loss: 0.079\n",
            "[3,     7] loss: 0.090\n",
            "[3,     8] loss: 0.078\n",
            "[3,     9] loss: 0.075\n",
            "[3,    10] loss: 0.079\n",
            "[3,    11] loss: 0.080\n",
            "[3,    12] loss: 0.078\n",
            "[3,    13] loss: 0.068\n",
            "[3,    14] loss: 0.074\n",
            "[3,    15] loss: 0.080\n",
            "[3,    16] loss: 0.078\n",
            "[3,    17] loss: 0.085\n",
            "[3,    18] loss: 0.080\n",
            "[3,    19] loss: 0.084\n",
            "[3,    20] loss: 0.076\n",
            "[3,    21] loss: 0.076\n",
            "[3,    22] loss: 0.081\n",
            "[3,    23] loss: 0.077\n",
            "[3,    24] loss: 0.067\n",
            "[3,    25] loss: 0.073\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([8, 1000]), labels shape: torch.Size([8, 1000])\n",
            "correct 142251 / 200000\n",
            "Valid accuracy: 71 %\n",
            "best_val_acc: 71.1255 saving model at data/pointnet/checkpoints/pointnetmodel.yml\n",
            "[4,     1] loss: 0.074\n",
            "[4,     2] loss: 0.071\n",
            "[4,     3] loss: 0.077\n",
            "[4,     4] loss: 0.072\n",
            "[4,     5] loss: 0.075\n",
            "[4,     6] loss: 0.065\n",
            "[4,     7] loss: 0.076\n",
            "[4,     8] loss: 0.074\n",
            "[4,     9] loss: 0.078\n",
            "[4,    10] loss: 0.068\n",
            "[4,    11] loss: 0.075\n",
            "[4,    12] loss: 0.074\n",
            "[4,    13] loss: 0.081\n",
            "[4,    14] loss: 0.074\n",
            "[4,    15] loss: 0.074\n",
            "[4,    16] loss: 0.069\n",
            "[4,    17] loss: 0.077\n",
            "[4,    18] loss: 0.068\n",
            "[4,    19] loss: 0.068\n",
            "[4,    20] loss: 0.085\n",
            "[4,    21] loss: 0.076\n",
            "[4,    22] loss: 0.067\n",
            "[4,    23] loss: 0.064\n",
            "[4,    24] loss: 0.064\n",
            "[4,    25] loss: 0.077\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([8, 1000]), labels shape: torch.Size([8, 1000])\n",
            "correct 149586 / 200000\n",
            "Valid accuracy: 74 %\n",
            "best_val_acc: 74.793 saving model at data/pointnet/checkpoints/pointnetmodel.yml\n",
            "[5,     1] loss: 0.073\n",
            "[5,     2] loss: 0.070\n",
            "[5,     3] loss: 0.066\n",
            "[5,     4] loss: 0.060\n",
            "[5,     5] loss: 0.067\n",
            "[5,     6] loss: 0.066\n",
            "[5,     7] loss: 0.062\n",
            "[5,     8] loss: 0.063\n",
            "[5,     9] loss: 0.060\n",
            "[5,    10] loss: 0.064\n",
            "[5,    11] loss: 0.066\n",
            "[5,    12] loss: 0.070\n",
            "[5,    13] loss: 0.062\n",
            "[5,    14] loss: 0.068\n",
            "[5,    15] loss: 0.076\n",
            "[5,    16] loss: 0.061\n",
            "[5,    17] loss: 0.061\n",
            "[5,    18] loss: 0.062\n",
            "[5,    19] loss: 0.062\n",
            "[5,    20] loss: 0.066\n",
            "[5,    21] loss: 0.064\n",
            "[5,    22] loss: 0.055\n",
            "[5,    23] loss: 0.059\n",
            "[5,    24] loss: 0.066\n",
            "[5,    25] loss: 0.055\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([8, 1000]), labels shape: torch.Size([8, 1000])\n",
            "correct 152002 / 200000\n",
            "Valid accuracy: 76 %\n",
            "best_val_acc: 76.001 saving model at data/pointnet/checkpoints/pointnetmodel.yml\n",
            "[6,     1] loss: 0.063\n",
            "[6,     2] loss: 0.059\n",
            "[6,     3] loss: 0.059\n",
            "[6,     4] loss: 0.066\n",
            "[6,     5] loss: 0.058\n",
            "[6,     6] loss: 0.064\n",
            "[6,     7] loss: 0.061\n",
            "[6,     8] loss: 0.055\n",
            "[6,     9] loss: 0.060\n",
            "[6,    10] loss: 0.060\n",
            "[6,    11] loss: 0.056\n",
            "[6,    12] loss: 0.067\n",
            "[6,    13] loss: 0.057\n",
            "[6,    14] loss: 0.063\n",
            "[6,    15] loss: 0.062\n",
            "[6,    16] loss: 0.062\n",
            "[6,    17] loss: 0.062\n",
            "[6,    18] loss: 0.057\n",
            "[6,    19] loss: 0.053\n",
            "[6,    20] loss: 0.056\n",
            "[6,    21] loss: 0.058\n",
            "[6,    22] loss: 0.060\n",
            "[6,    23] loss: 0.052\n",
            "[6,    24] loss: 0.053\n",
            "[6,    25] loss: 0.058\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([8, 1000]), labels shape: torch.Size([8, 1000])\n",
            "correct 155877 / 200000\n",
            "Valid accuracy: 77 %\n",
            "best_val_acc: 77.9385 saving model at data/pointnet/checkpoints/pointnetmodel.yml\n",
            "[7,     1] loss: 0.052\n",
            "[7,     2] loss: 0.067\n",
            "[7,     3] loss: 0.060\n",
            "[7,     4] loss: 0.057\n",
            "[7,     5] loss: 0.053\n",
            "[7,     6] loss: 0.058\n",
            "[7,     7] loss: 0.053\n",
            "[7,     8] loss: 0.053\n",
            "[7,     9] loss: 0.050\n",
            "[7,    10] loss: 0.054\n",
            "[7,    11] loss: 0.064\n",
            "[7,    12] loss: 0.058\n",
            "[7,    13] loss: 0.051\n",
            "[7,    14] loss: 0.060\n",
            "[7,    15] loss: 0.054\n",
            "[7,    16] loss: 0.052\n",
            "[7,    17] loss: 0.054\n",
            "[7,    18] loss: 0.057\n",
            "[7,    19] loss: 0.055\n",
            "[7,    20] loss: 0.064\n",
            "[7,    21] loss: 0.054\n",
            "[7,    22] loss: 0.051\n",
            "[7,    23] loss: 0.060\n",
            "[7,    24] loss: 0.056\n",
            "[7,    25] loss: 0.060\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([8, 1000]), labels shape: torch.Size([8, 1000])\n",
            "correct 155950 / 200000\n",
            "Valid accuracy: 77 %\n",
            "best_val_acc: 77.975 saving model at data/pointnet/checkpoints/pointnetmodel.yml\n",
            "[8,     1] loss: 0.054\n",
            "[8,     2] loss: 0.054\n",
            "[8,     3] loss: 0.046\n",
            "[8,     4] loss: 0.050\n",
            "[8,     5] loss: 0.058\n",
            "[8,     6] loss: 0.058\n",
            "[8,     7] loss: 0.056\n",
            "[8,     8] loss: 0.056\n",
            "[8,     9] loss: 0.047\n",
            "[8,    10] loss: 0.056\n",
            "[8,    11] loss: 0.051\n",
            "[8,    12] loss: 0.053\n",
            "[8,    13] loss: 0.051\n",
            "[8,    14] loss: 0.057\n",
            "[8,    15] loss: 0.053\n",
            "[8,    16] loss: 0.048\n",
            "[8,    17] loss: 0.054\n",
            "[8,    18] loss: 0.055\n",
            "[8,    19] loss: 0.051\n",
            "[8,    20] loss: 0.057\n",
            "[8,    21] loss: 0.052\n",
            "[8,    22] loss: 0.048\n",
            "[8,    23] loss: 0.051\n",
            "[8,    24] loss: 0.048\n",
            "[8,    25] loss: 0.058\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([8, 1000]), labels shape: torch.Size([8, 1000])\n",
            "correct 160377 / 200000\n",
            "Valid accuracy: 80 %\n",
            "best_val_acc: 80.1885 saving model at data/pointnet/checkpoints/pointnetmodel.yml\n",
            "[9,     1] loss: 0.057\n",
            "[9,     2] loss: 0.051\n",
            "[9,     3] loss: 0.043\n",
            "[9,     4] loss: 0.051\n",
            "[9,     5] loss: 0.047\n",
            "[9,     6] loss: 0.050\n",
            "[9,     7] loss: 0.056\n",
            "[9,     8] loss: 0.052\n",
            "[9,     9] loss: 0.048\n",
            "[9,    10] loss: 0.049\n",
            "[9,    11] loss: 0.050\n",
            "[9,    12] loss: 0.050\n",
            "[9,    13] loss: 0.054\n",
            "[9,    14] loss: 0.051\n",
            "[9,    15] loss: 0.050\n",
            "[9,    16] loss: 0.045\n",
            "[9,    17] loss: 0.049\n",
            "[9,    18] loss: 0.051\n",
            "[9,    19] loss: 0.044\n",
            "[9,    20] loss: 0.054\n",
            "[9,    21] loss: 0.059\n",
            "[9,    22] loss: 0.054\n",
            "[9,    23] loss: 0.051\n",
            "[9,    24] loss: 0.053\n",
            "[9,    25] loss: 0.050\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([8, 1000]), labels shape: torch.Size([8, 1000])\n",
            "correct 162252 / 200000\n",
            "Valid accuracy: 81 %\n",
            "best_val_acc: 81.126 saving model at data/pointnet/checkpoints/pointnetmodel.yml\n",
            "[10,     1] loss: 0.047\n",
            "[10,     2] loss: 0.053\n",
            "[10,     3] loss: 0.052\n",
            "[10,     4] loss: 0.045\n",
            "[10,     5] loss: 0.041\n",
            "[10,     6] loss: 0.056\n",
            "[10,     7] loss: 0.050\n",
            "[10,     8] loss: 0.047\n",
            "[10,     9] loss: 0.058\n",
            "[10,    10] loss: 0.050\n",
            "[10,    11] loss: 0.041\n",
            "[10,    12] loss: 0.047\n",
            "[10,    13] loss: 0.047\n",
            "[10,    14] loss: 0.045\n",
            "[10,    15] loss: 0.049\n",
            "[10,    16] loss: 0.053\n",
            "[10,    17] loss: 0.044\n",
            "[10,    18] loss: 0.056\n",
            "[10,    19] loss: 0.045\n",
            "[10,    20] loss: 0.045\n",
            "[10,    21] loss: 0.045\n",
            "[10,    22] loss: 0.051\n",
            "[10,    23] loss: 0.041\n",
            "[10,    24] loss: 0.047\n",
            "[10,    25] loss: 0.047\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([8, 1000]), labels shape: torch.Size([8, 1000])\n",
            "correct 162340 / 200000\n",
            "Valid accuracy: 81 %\n",
            "best_val_acc: 81.17 saving model at data/pointnet/checkpoints/pointnetmodel.yml\n",
            "[11,     1] loss: 0.050\n",
            "[11,     2] loss: 0.043\n",
            "[11,     3] loss: 0.049\n",
            "[11,     4] loss: 0.045\n",
            "[11,     5] loss: 0.055\n",
            "[11,     6] loss: 0.046\n",
            "[11,     7] loss: 0.045\n",
            "[11,     8] loss: 0.047\n",
            "[11,     9] loss: 0.047\n",
            "[11,    10] loss: 0.042\n",
            "[11,    11] loss: 0.045\n",
            "[11,    12] loss: 0.046\n",
            "[11,    13] loss: 0.043\n",
            "[11,    14] loss: 0.045\n",
            "[11,    15] loss: 0.044\n",
            "[11,    16] loss: 0.044\n",
            "[11,    17] loss: 0.044\n",
            "[11,    18] loss: 0.053\n",
            "[11,    19] loss: 0.045\n",
            "[11,    20] loss: 0.054\n",
            "[11,    21] loss: 0.040\n",
            "[11,    22] loss: 0.041\n",
            "[11,    23] loss: 0.049\n",
            "[11,    24] loss: 0.047\n",
            "[11,    25] loss: 0.050\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([8, 1000]), labels shape: torch.Size([8, 1000])\n",
            "correct 160272 / 200000\n",
            "Valid accuracy: 80 %\n",
            "[12,     1] loss: 0.040\n",
            "[12,     2] loss: 0.052\n",
            "[12,     3] loss: 0.048\n",
            "[12,     4] loss: 0.056\n",
            "[12,     5] loss: 0.046\n",
            "[12,     6] loss: 0.040\n",
            "[12,     7] loss: 0.045\n",
            "[12,     8] loss: 0.046\n",
            "[12,     9] loss: 0.044\n",
            "[12,    10] loss: 0.046\n",
            "[12,    11] loss: 0.049\n",
            "[12,    12] loss: 0.042\n",
            "[12,    13] loss: 0.054\n",
            "[12,    14] loss: 0.038\n",
            "[12,    15] loss: 0.063\n",
            "[12,    16] loss: 0.049\n",
            "[12,    17] loss: 0.042\n",
            "[12,    18] loss: 0.043\n",
            "[12,    19] loss: 0.040\n",
            "[12,    20] loss: 0.042\n",
            "[12,    21] loss: 0.043\n",
            "[12,    22] loss: 0.044\n",
            "[12,    23] loss: 0.038\n",
            "[12,    24] loss: 0.043\n",
            "[12,    25] loss: 0.051\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([8, 1000]), labels shape: torch.Size([8, 1000])\n",
            "correct 163927 / 200000\n",
            "Valid accuracy: 81 %\n",
            "best_val_acc: 81.9635 saving model at data/pointnet/checkpoints/pointnetmodel.yml\n",
            "[13,     1] loss: 0.047\n",
            "[13,     2] loss: 0.043\n",
            "[13,     3] loss: 0.041\n",
            "[13,     4] loss: 0.037\n",
            "[13,     5] loss: 0.042\n",
            "[13,     6] loss: 0.039\n",
            "[13,     7] loss: 0.045\n",
            "[13,     8] loss: 0.049\n",
            "[13,     9] loss: 0.045\n",
            "[13,    10] loss: 0.049\n",
            "[13,    11] loss: 0.040\n",
            "[13,    12] loss: 0.042\n",
            "[13,    13] loss: 0.037\n",
            "[13,    14] loss: 0.044\n",
            "[13,    15] loss: 0.045\n",
            "[13,    16] loss: 0.044\n",
            "[13,    17] loss: 0.042\n",
            "[13,    18] loss: 0.049\n",
            "[13,    19] loss: 0.042\n",
            "[13,    20] loss: 0.041\n",
            "[13,    21] loss: 0.046\n",
            "[13,    22] loss: 0.043\n",
            "[13,    23] loss: 0.048\n",
            "[13,    24] loss: 0.045\n",
            "[13,    25] loss: 0.041\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([32, 1000]), labels shape: torch.Size([32, 1000])\n",
            "predicted shape: torch.Size([8, 1000]), labels shape: torch.Size([8, 1000])\n",
            "correct 165334 / 200000\n",
            "Valid accuracy: 82 %\n",
            "best_val_acc: 82.667 saving model at data/pointnet/checkpoints/pointnetmodel.yml\n",
            "[14,     1] loss: 0.044\n",
            "[14,     2] loss: 0.048\n",
            "[14,     3] loss: 0.045\n"
          ]
        }
      ],
      "source": [
        "from ai.pointnet_seg.train import train\n",
        "from ai.pointnet_seg.model import PointNetSeg\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "segmenter = PointNetSeg(classes=n_classes)\n",
        "\n",
        "train(\n",
        "    pointnet=segmenter,\n",
        "    optimizer=torch.optim.Adam(segmenter.parameters(), lr=0.001),\n",
        "    train_data=DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4),\n",
        "    eval_data=DataLoader(eval_dataset, batch_size=32, shuffle=False, num_workers=4),\n",
        "    out_dir=\"data/pointnet/checkpoints\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing\n",
        "\n",
        "Test our data on our real-world dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ai.pointnet_seg.test import test\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "test(\n",
        "    model=segmenter,\n",
        "    test_data=DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4),\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
