{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Ensure all dependencies are installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting m2p (from -r requirements.txt (line 12))\n",
      "  Cloning ssh://****@gitlab.utwente.nl/s2219735-bsc-research-project/mesh-to-points.git (to revision main) to /tmp/pip-install-hqxg6667/m2p_d851e24dc487432cabd9c86da5523f23\n",
      "  Running command git clone --filter=blob:none --quiet 'ssh://****@gitlab.utwente.nl/s2219735-bsc-research-project/mesh-to-points.git' /tmp/pip-install-hqxg6667/m2p_d851e24dc487432cabd9c86da5523f23\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we have GPU support, and if not, warn the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import warnings\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    warnings.warn(\"CUDA is not available. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our dataset...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Checking for existing source data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 1/12311 [00:00<2:20:04,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 2/12311 [00:01<2:26:59,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 3/12311 [00:02<2:24:44,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 5/12311 [00:02<1:28:47,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n",
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 6/12311 [00:02<1:13:51,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n",
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 8/12311 [00:03<56:38,  3.62it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 9/12311 [00:03<1:05:28,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 10/12311 [00:04<1:02:52,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 11/12311 [00:04<1:10:29,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 12/12311 [00:04<1:13:51,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n",
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 14/12311 [00:05<55:53,  3.67it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 15/12311 [00:06<1:38:38,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n",
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 17/12311 [00:06<1:08:40,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 18/12311 [00:07<1:16:23,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 19/12311 [00:07<1:15:34,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 20/12311 [00:08<2:18:29,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 21/12311 [00:09<2:08:35,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 22/12311 [00:09<2:11:29,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 23/12311 [00:10<2:01:34,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 24/12311 [00:11<2:18:35,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 25/12311 [00:11<2:05:14,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 26/12311 [00:12<1:51:50,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 27/12311 [00:12<1:45:13,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n",
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 29/12311 [00:13<1:42:01,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 32/12311 [00:13<57:59,  3.53it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n",
      "PointCloud with 2500 points.\n",
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 33/12311 [00:14<1:15:01,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 34/12311 [00:14<1:07:48,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 35/12311 [00:15<1:17:22,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2500 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 35/12311 [00:18<1:48:06,  1.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 29\u001b[0m     classes, train_dataset, test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mModelNet40\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_outdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_outdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_folder\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(classes)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\julia\\src\\research-project-python\\data_sources\\modelnet40.py:102\u001b[0m, in \u001b[0;36mModelNet40.download\u001b[1;34m(cls, npoints, train_outdir, test_outdir)\u001b[0m\n\u001b[0;32m    100\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(split_folder, file)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Annoying but we need to do this to fix some OFF files\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m mesh \u001b[38;5;241m=\u001b[39m \u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_triangle_mesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m pcd \u001b[38;5;241m=\u001b[39m mesh\u001b[38;5;241m.\u001b[39msample_points_uniformly(number_of_points\u001b[38;5;241m=\u001b[39mnpoints)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(pcd)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from data_sources.modelnet40 import ModelNet40\n",
    "from models.dataset import PointCloudDataset\n",
    "from typing import List\n",
    "\n",
    "train_folder = \"data/train\"\n",
    "test_folder = \"data/test\"\n",
    "\n",
    "train_dataset: PointCloudDataset = None\n",
    "test_dataset: PointCloudDataset = None\n",
    "\n",
    "if os.path.exists(train_folder) and os.path.exists(test_folder):\n",
    "    print(\"Train and test data found. Reading data...\")\n",
    "    train_files: List[str] = []\n",
    "    test_files: List[str] = []\n",
    "\n",
    "    for root, dirs, files in os.walk(train_folder):\n",
    "        for file in files:\n",
    "            train_files.append(os.path.join(root, file))\n",
    "\n",
    "    for root, dirs, files in os.walk(test_folder):\n",
    "        for file in files:\n",
    "            test_files.append(os.path.join(root, file))\n",
    "\n",
    "    train_dataset = PointCloudDataset(train_files)\n",
    "    test_dataset = PointCloudDataset(test_files)\n",
    "    k = 40\n",
    "else:\n",
    "    classes, train_dataset, test_dataset = ModelNet40.download(\n",
    "        npoints=2500, train_outdir=train_folder, test_outdir=test_folder\n",
    "    )\n",
    "    k = len(classes)\n",
    "\n",
    "print(f\"Training data: {len(train_dataset)} samples\")\n",
    "print(f\"Test data size: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Train a new classifier or load a new pre-trained one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  7870\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PointCloudDataset' object has no attribute 'classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassifier loaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     classifier \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_classification\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./pointnet/cls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/research-project-python/pointnet/train_classification.py:45\u001b[0m, in \u001b[0;36mtrain_classification\u001b[0;34m(train_dataset, test_dataset, batchSize, workers, epochs, outf, model, feature_transform)\u001b[0m\n\u001b[1;32m     34\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m     35\u001b[0m     train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatchSize, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39mworkers\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     38\u001b[0m testdataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m     39\u001b[0m     test_dataset,\n\u001b[1;32m     40\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatchSize,\n\u001b[1;32m     41\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     42\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39mworkers,\n\u001b[1;32m     43\u001b[0m )\n\u001b[0;32m---> 45\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(outf)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PointCloudDataset' object has no attribute 'classes'"
     ]
    }
   ],
   "source": [
    "from pointnet.train_classification import train_classification\n",
    "from pointnet.model import PointNetCls\n",
    "\n",
    "classifier_path = \"\"  # pointnet/classifier.pth\n",
    "\n",
    "if classifier_path and os.path.exists(classifier_path):\n",
    "    print(f\"Loading existing model from {classifier_path}...\")\n",
    "    classifier = PointNetCls(k=len(train_dataset.classes))\n",
    "    classifier.load_state_dict(torch.load(classifier_path, weights_only=True))\n",
    "    print(\"Classifier loaded successfully.\")\n",
    "else:\n",
    "    classifier = train_classification(\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        k=k,\n",
    "        epochs=25,\n",
    "        outf=\"./pointnet/cls\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a simple classification to get a visualization of our classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from utils.plot import plot_points\n",
    "\n",
    "i = random.randint(0, len(test_dataset) - 1)\n",
    "\n",
    "input_data = test_dataset[i][0].unsqueeze(0)\n",
    "input_data = input_data.transpose(1, 2)\n",
    "\n",
    "classifier.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = classifier(input_data)\n",
    "\n",
    "\n",
    "scores: torch.Tensor = output[0][0]\n",
    "print(\"Scores:\", scores.tolist())\n",
    "print(\n",
    "    f\"Expected class: {test_dataset.classes[int(test_dataset[i][1])]} ({int(test_dataset[i][1])})\",\n",
    ")\n",
    "print(\n",
    "    f\"Predicted class: {test_dataset.classes[scores.argmax().item()]} ({scores.argmax().item()})\"\n",
    ")\n",
    "\n",
    "points = input_data[0].transpose(0, 1).numpy()\n",
    "plot_points(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the segmenter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pointnet.train_segmentation import train_segmentation\n",
    "\n",
    "train_segmentation(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    epochs=25,\n",
    "    class_choice=0,\n",
    "    outf=\"./pointnet/seg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
